Reduced version of RadioAnalysis for GRAND reconstruction and modifications based on simulations
Will mainly contain the main files needed for these purposes while leaving out the rest of the old repository

# Installation
Many ways you could set it up, but my recommendation is a virtual environment with

- locally installed ROOT (follow instructions on official ROOT website and download the right build for you)
- GRANDlib inside the environment which includes turtle and gull for coordinate trafos (ask people in the collaboration to help you with setting it up)
- python version (needs to match ROOT version!!) installed in the environment with .pth files for the required packages 

Currently, the repo works with ROOT 6.36 and python 3.10.12

## Specifically, you need these modules:

Some pip modules needed (install with pip --user install <module>):

- iminuit, lmfit, scipy, numpy, matplotlib, ray

External packages needed for full usage of reconstuction: 

 - radiotools (https://github.com/nu-radio/radiotools.git) (get github version for GRAND atmosphere model, labelled 41)
 - GRANDlib (for any interactions with simulations processed by GRAND or measurement data)
    (https://github.com/grand-mother/grand.git "dev" branch [status: 28.11.2025])
 - electric field reconstruction (for realistic ADC trace simulations and measurement data)
    (https://github.com/grand-mother/E-Field-reconstruction-preliminary for a method from Kewen Zhang, modified by Lukas Gülzow)
 - PWF_reconstruction (for reconstruction of arrival direction)
    (https://github.com/arsenefer/PWF_reconstruction.git)

Clone them (with "git clone") and add them to your PYTHONPATH environmental variable

You have to add the root path of this project to your PYTHONPATH, i.e.,
export PYTHONPATH=$PYTHONPATH:/path/to/RadioAnalysis


# Framework and Data Storage
The "framework" folder contains the important classes for organisation and data storage:

parameter_storage: list of named parameters under which data and reconstructed values can be saved on event, shower and antenna scale

event & revent: classes to handle simulated and measured events including many functions to extract and save data in the form of named parameters

shower: initialisable shower class to store more specific shower parameters

factory: class to handle and store many events at once

## Data storage
Event data and reconstructed parameters can be saved from the factory class format into .pickle files for later use without rerunnning reconstruction or any other calculations
Read in .pickle files again to reinitialise factory object


# Reconstruction
Long chain of files using almost all parts of this repository.
Starts either with "LDF_fit_single_file" for single files or "LDF_fit_parallel" for many files parallelised.
Measurement data is processed with the single-file pipeline, but can be extended and parallelised if necessary for bigger data load.
Parallel pipeline is made for evaluating the reconstruction with a large number of simulated events, as well as tuning the model parameters.


## Parallel pipelines

Parallel pipeline is set up as a sequence of .sh scripts:
- for hdf5: *prefit.sh* -> *execute_fit_over_all_sims.sh* -> *reconstruction_eval.sh*
- for GRANDROOT: *read_root_files.sh* -> *prefit.sh* -> *execute_fit_over_all_sims.sh* -> *reconstruction_eval.sh*

In these scripts you can change some of the pipeline variables, like the atmosphere model and whether you using idealistic or realistic input.
These input modes decide whether you use MC data or reconstructed/estimated values for arrival direction, core position, and Xmax.


Other parameters and functionalities of the pipelines have to be changed in the functions the scripts are calling:

In *root_reader.py*, you can choose whether:
- to reconstruct the efield or use efield from Corsika (l. 538)
- to use MC shower data for the reconstruction (l. 539)
- to save the reconstructed efield traces in .npz files (l. 541)
- to calculate the fluence from CORSIKA to compare with the fluence from reconstructed efield traces (l. 542)

In *ldf_fitting.py*, you call the function *_fit_param_has_ldf*. There you can decide:
- whether to use fluence uncertainties determined from the traces or an uncertainty model (l. 666)
- which output to use for the title of LDF plots (l. 838 onwards)
- on which LDF parameters to fix to their parametrisation (l. 777-788)

Importantly, for accurate energy reconstruction output on the LDF plots, you need to match the energy reconstruction parameters in this file to the ones in *ldf_evaluation.py*. There you can tune them with a fit, if you decide to adjust the model.

In *ldf_plotting.py*, you can adjust the single LDF plots.

In *ldf_evaluation.py*, you can output the parallel pipeline for many events and evaluate the collective fit results and adjust the energy reconstruction.
The file is very long, but sectioned into each functionality. The main function is *evaluate_fit_result*.


## Example commands:

### Single files, valid for data and sims:

- reconstruction and ldf fit of a single file in hdf5 format: *python [path_to_radiominimalysis]/scripts/LDF_fit_single_file.py --atmModel 41 --plot [path_to_hdf5_sim]*
- reconstruction and ldf fit of an event or events in GRANDROOT format: *python [path_to_radiominimalysis]/scripts/LDF_fit_single_file.py -m 41 -p [path_to_ROOT]*

For real measurements, you have to add the option "-real" to enable to realistic_input pipeline

### Parallel
Central file: *RAY_parallel_functions.py*

Keep in mind that you have to adjust path according to your system and data storage locations.
In the .sh scripts, you have to choose the path to your data as well as file names for the .pickle files.
The location where the .pickle files are stored, can be set in *RAY_parallel_functions.py* (l. 247).

- (optional) Read in GRANDROOT files: *[path to radiominimalysis]/scripts/read_root_files.sh* 
- (start here for .hdf5 input files) Perform geometry calculations necessary for LDF fit: *[path to radiominimalysis]/scripts/pre_fit.sh*
- Perform LDF fit for all events: *[path to radiominimalysis]/scripts/execute_fit_over_all_sims.sh*
- Evaluate LDF fit results: *[path to radiominimalysis]/scripts/reconstruction_eval.sh*


# Scripts
Usage of the python scripts included in this repository:

- *CE_charge_excess_eval.py*: Evaluation of charge excess fraction parametrisation
- *CE_charge_excess_eparam_new.py*: Enables new fit of charge excess fraction parametrisation
- *check_cherenkov_radii.sh*: Calls *CR_cherenkov_comparison.py* for given completed LDF fits, which evaluates the offset from the theoretically predicted Cherenkov angle for the radio emission
- *ER_reconstruct_energy_from_pickle.py*: Called by *reconstruction_eval.sh*. Choose inside which parts of reconstruction to evaluate
- *FP_fluence_step-by-step.py*: Plot interpolated fluence footprints for an .hdf5 file, in the sequence the model isolates the geomagnetic emission


# Model Tuning
To be expanded...

## Charge Excess Fraction
Use star-shape simulations and positional determination of geomagnetic radio emission component (For details, see PhD theses of Felix Schlüter or Lukas Gülzow)

## Parametrisation of LDF shape parameters with dmax
Use parallel pipeline while leaving LDF shape parameters free. Visualise parameters with *gauss_sigmoid_param.py*.
(For details, see PhD theses of Felix Schlüter or Lukas Gülzow)